{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "liarplus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smara97/FakeNews/blob/master/liarplus-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8QmECF_eHE",
        "colab_type": "code",
        "outputId": "7022628f-b7cb-4c92-b0ac-7a727073b5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from google.colab import files,drive\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import wordpunct_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from torch.autograd import Variable\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "import nltk\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k39R3AAAADa8",
        "colab_type": "code",
        "outputId": "37e834e7-b51b-4ff9-a516-2fe088534e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3HBqw4Onjsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Model to Training Data \n",
        "\n",
        "  Forward Function\n",
        "Take length of Embedding and Dim of it and Create Embedding Layer by torch Framework\n",
        "Create Neural Network Layer take 903 input and return 256 as output layer\n",
        "then bass output to non-activation function layer then add dropout to output\n",
        "bass output to Linear take 256 and return number of class 1 and then add sigmoid to output\n",
        "\n",
        "  Conv Function \n",
        "Take inputs ( self, inputs layer[batch size of training inputs*Featuers] (64,1440) )\n",
        "\n",
        "conv inputs layer from [64,1440] to [64,903]\n",
        "\n",
        "first 300s number repersent the vector sentence(Statement) of Embedding\n",
        "\n",
        "301 add Similarity of Statement Featuer (first [410] numbers of orignal input) and \n",
        "  Subject Featuer (second [30] numbers of orignal input)\n",
        "\n",
        "from 302 to 602 add number repersent the vector sentence(Subject) of Embedding\n",
        "\n",
        "602 add Similarity of Subject Featuer ([30] numbers of orignal input) and \n",
        "  Justification Featuer (second [1000] numbers of orignal input)\n",
        "\n",
        "from 602 to 902 add number repersent the vector sentence(Justifaction) of Embedding\n",
        "\n",
        "903 add Similarity of Justification Featuer ([100] numbers of orignal input) and \n",
        "  Statement Featuer (second [410] numbers of orignal input)\n",
        "\n",
        "and return [64,903]\n",
        "\n",
        "Then Pass output of Conv to Forward\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim,word_embedding):\n",
        "\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "        \n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)   \n",
        "    self.embedding.weight.data.copy_(word_embedding)\n",
        "\n",
        "    self.conv1=nn.Conv1d(903,out_channels=embedding_dim, kernel_size=2,padding=1)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.dropout1=nn.Dropout(0.6)\n",
        "\n",
        "    self.conv2 = nn.Conv1d(embedding_dim, out_channels=embedding_dim, kernel_size=3,padding=1)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.dropout2=nn.Dropout(0.6)\n",
        "\n",
        "    self.conv3 = nn.Conv1d(embedding_dim, out_channels=embedding_dim, kernel_size=4,padding=1)\n",
        "    self.maxpool3 = nn.AvgPool1d(kernel_size=2, stride=1, padding=1)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.dropout3=nn.Dropout(0.6)\n",
        "\n",
        "    self.fc=nn.Linear(600,1)\n",
        "    self.dropout4=nn.Dropout(0.5)\n",
        "    self.sig=nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    x = self.conv(x)\n",
        "    x = x.transpose(0,1).transpose(1,2)\n",
        "    \n",
        "    out=self.dropout1(self.relu1(self.conv1(x)))\n",
        "    out=self.dropout2(self.relu2(self.conv2(out)))\n",
        "    out=self.dropout3(self.maxpool3(self.relu3(self.conv3(out))))\n",
        "    out=self.dropout4(out)\n",
        "    out=out.reshape(out.size(0), -1)\n",
        "    return self.sig(self.fc(out))\n",
        "    \n",
        "  def conv(self,x):\n",
        "    batch=len(x)\n",
        "\n",
        "    ret=torch.zeros((batch,903)).cuda()\n",
        "    st=torch.zeros(300).cuda()\n",
        "    su=torch.zeros(300).cuda()\n",
        "    ju=torch.zeros(300).cuda()\n",
        "\n",
        "\n",
        "    \n",
        "    for i in range(batch):\n",
        "  \n",
        "      st=self.embedding(x[i][0:411]).sum(dim=0)/(x[i][0:411]!=0).sum()\n",
        "      su=self.embedding(x[i][411:441]).sum(dim=0)/(x[i][411:441]!=0).sum()\n",
        "      ju=self.embedding(x[i][441:1440]).sum(dim=0)/(x[i][441:1440]!=0).sum()\n",
        "      \n",
        "      ret[i][:300]=st\n",
        "      ret[i][300]=simlarity(st,su)\n",
        "\n",
        "      ret[i][301:601]=su\n",
        "      ret[i][601]=simlarity(su,ju)\n",
        "\n",
        "      ret[i][602:902]=ju\n",
        "      \n",
        "      ret[i][902]=simlarity(st,ju)\n",
        "    return ret.view(1,batch,903)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LpKF7Bj6Hw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        " Read Glove File take url of file return the two dictionaries ( word to index and word to vector in embedding )\n",
        " and one list of index to word  \n",
        " (glove file url) --> words_to_index, index_to_words, word_to_vec_map\n",
        " \n",
        " \"\"\"\n",
        "\n",
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r',encoding='UTF-8') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_YGt1t36NVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Word Embeddings of words take dictionary of word to embedding and word to index\n",
        "and return Embeddings Matrix [index,Embedding] \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_len = len(word_to_index) + 1\n",
        "    emb_matrix = np.zeros((vocab_len,300))\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "    return emb_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG5u2iTih9ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Clean Text \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def clean(text):\n",
        "  text=text.lower()\n",
        "  stp=set(stopwords.words(\"english\"))\n",
        "  placesp = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "  removech= re.compile('[^0-9a-z #+_]')\n",
        "  st=WordNetLemmatizer()\n",
        "  text=re.sub(placesp,' ',text)\n",
        "  text=re.sub(removech,' ',text)\n",
        "  text=text.split()\n",
        "  text=[w for w in text if not w in stp]\n",
        "  text=[st.lemmatize(w) for w in text]\n",
        "  text=\" \".join(text)\n",
        "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyXAjL26LJxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Transfer sentence to indeces word in Embedding\n",
        "take text and word to index dictionary \n",
        "return list of indeces word in Embedding\n",
        "\n",
        "\"\"\"\n",
        "def transfer_sent(text,word_to_index):\n",
        "  text=text.split(' ')\n",
        "  ret=[]\n",
        "  for w in text:\n",
        "    if w in word_to_index and w !=\"\":\n",
        "      ret.append(word_to_index[w])\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAFkt1gUUIkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Similarity of two Documnets \n",
        "take two documnets\n",
        "return The Similarity of documents\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def simlarity(dim1,dim2):\n",
        "  return (torch.dot(dim1,dim2)/(torch.sqrt(torch.sum(dim1**2))*torch.sqrt(torch.sum(dim2**2))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owt9-oD4iutn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Accuracy of predict labels\n",
        "take predict labels and target labels\n",
        "return number of accept label in predict labels\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def Accu(pred,labels):\n",
        "  ret=0\n",
        "  for i in range(len(labels)):\n",
        "    if pred[i]==labels[i]:\n",
        "      ret+=1\n",
        "  return ret/len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6FmfbWRwwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "calculate the Max Length in every column in Data Frame \n",
        "take Data Frame \n",
        "return Max lenght of columns\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def retmax(dftrain):\n",
        "\n",
        "  stmax,sumax,jumax=0,0,0\n",
        "  for i in range(dftrain.shape[0]):\n",
        "\n",
        "    stmax=max(stmax,len(np.array(dftrain.loc[i,'statement'])))\n",
        "\n",
        "    sumax=max(sumax,len(np.array(dftrain.loc[i,'subject'])))\n",
        "\n",
        "    jumax=max(jumax,len(np.array(dftrain.loc[i,'justification'])))\n",
        "\n",
        "  return stmax,sumax,jumax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GG5byD7ZbBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convert Data Frame to Matrix 2D by Adding padding zeros to every columns that not have lenght not equal max\n",
        "lenght.\n",
        "take Data Frame list of Max Lenghts of Columns\n",
        "return Matrix after convert\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def convert2D(Xs,max_lens):\n",
        "   X_indices = np.zeros((Xs[0].shape[0], sum(max_lens)))\n",
        "   pls=0\n",
        "\n",
        "   for i in range(Xs[0].shape[0]):\n",
        "     pls=0\n",
        "     \n",
        "     for j in range(0,len(Xs[0][i])):\n",
        "       X_indices[i][j+pls]=Xs[0][i][j]\n",
        "     pls=max_lens[0]\n",
        "\n",
        "     for j in range(0,len(Xs[1][i])):\n",
        "       X_indices[i][j+pls+1]=Xs[1][i][j]\n",
        "     pls=max_lens[1]+max_lens[0]\n",
        "\n",
        "     for j in range(0,len(Xs[2][i])):\n",
        "       X_indices[i][j+pls+1]=Xs[2][i][j]\n",
        "   return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C7Ej5cQNHUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "convert labels to 0,1 True or False  \n",
        "\n",
        "\"\"\"\n",
        "convertlabel = {\n",
        "\t'pants-fire': 0,\n",
        "\t'false': 0,\n",
        "\t'barely-true': 0,\n",
        "\t'half-true': 1,\n",
        "\t'mostly-true': 1,\n",
        "\t'true': 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvDjhEJ5AuqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "list of columns's Name \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cols=['index','ID','label','statement','subject','speaker',\n",
        "      'speaker_job','state','party','barely_true',\n",
        "      'false','half_true','mostly_true','pants_on_fire',\n",
        "      'context','justification']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmu1XWkeJ3gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Call read_glove_vecs function and then call pretrained_embedding_layer to calc word Embedding of Words\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(\"/content/drive/My Drive/Datasets/Word Embedding/glove.6B.300d.txt\")\n",
        "word_embedding=pretrained_embedding_layer(word_to_vec_map, word_to_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI1wca7kAHbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Read Dataset (Data Frame)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/train.tsv\",sep=\"\\t\",header=None)\n",
        "dfval=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/val.tsv\",sep=\"\\t\",header=None)\n",
        "dftest=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/test.tsv\",sep=\"\\t\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jZpxs8CIrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Add list cols to Data Frame columns\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain.columns=cols\n",
        "dfval.columns=cols\n",
        "dftest.columns=cols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCo9SEQ6SiQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Make Datasets have only statement,subject,justification and label \n",
        "important Feauters to Training\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=dftrain.loc[:,['statement','subject','justification','label']]\n",
        "dfval=dfval.loc[:,['statement','subject','justification','label']]\n",
        "dftest=dftest.loc[:,['statement','subject','justification','label']]\n",
        "dftrain=dftrain.append(dfval)\n",
        "dftrain=dftrain.append(dftest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiytTGihAnEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Drop NAN value and index column in Datasets \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=dftrain.dropna(axis=0)\n",
        "\n",
        "dftrain=dftrain.reset_index()\n",
        "\n",
        "dftrain=dftrain.drop(['index'],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlwxZGVZMi54",
        "colab_type": "code",
        "outputId": "91128c23-0811-444a-9ab5-c7889ba7d62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "\"\"\"  Show first two's row in dataset \"\"\"\n",
        "\n",
        "dftrain.head(2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>justification</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>That's a premise that he fails to back up. Ann...</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>Surovell said the decline of coal \"started whe...</td>\n",
              "      <td>half-true</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement  ...      label\n",
              "0  Says the Annies List political group supports ...  ...      false\n",
              "1  When did the decline of coal start? It started...  ...  half-true\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHJmQW1XNO-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convert Labels dataset to 0,1 by Call convertlabel Function , \n",
        "sentence to indeces by call transfer_sent Function\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for i in range(dftrain.shape[0]):\n",
        "  dftrain.loc[i,'label']=convertlabel[dftrain.loc[i,'label']]\n",
        "  dftrain.loc[i,'statement']=transfer_sent(clean(dftrain.loc[i,'statement']),word_to_index)\n",
        "  dftrain.loc[i,'subject']=transfer_sent(clean(dftrain.loc[i,'subject']),word_to_index)\n",
        "  dftrain.loc[i,'justification']=transfer_sent(clean(dftrain.loc[i,'justification']),word_to_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2rer47LEc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Take Labels two make only Target dataset and drop it in orignal dataset \"\"\"\n",
        "\n",
        "dftrainy=dftrain['label']\n",
        "\n",
        "dftrain=dftrain.drop(['label'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP-MvvSQU45O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Calc Max Lengths in every Columns by call retmax Function ,\n",
        "convert Data Frame to Matrix by convert2D Function\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "stmax,sumax,jumax=retmax(dftrain)\n",
        "Fulldata=np.array(convert2D([dftrain.statement,dftrain.subject,dftrain.justification],[410,30,1000]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGjc_T6CrFAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Split dataets to Training ,Validation and Testing Datasets \"\"\"\n",
        "\n",
        "dftrainy=list(dftrainy)\n",
        "training,trainingy=Fulldata[:10154],dftrainy[:10154]\n",
        "validation,validationy=Fulldata[10154:11784],dftrainy[10154:11784]\n",
        "testing,testingy=Fulldata[11785:],dftrainy[11785:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bInMSM2trKpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Convert every Datasets to Torch Datasets \"\"\"\n",
        "\n",
        "training=torch.from_numpy(training)\n",
        "trainingy = torch.tensor(trainingy) \n",
        "train_tensor = torch.utils.data.TensorDataset(training, trainingy)\n",
        "\n",
        "validation=torch.from_numpy(validation)\n",
        "validationy = torch.tensor(validationy) \n",
        "valid_tensor = torch.utils.data.TensorDataset(validation, validationy)\n",
        "\n",
        "testing=torch.from_numpy(testing)\n",
        "testingy = torch.tensor(testingy) \n",
        "test_tensor = torch.utils.data.TensorDataset(testing, testingy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT2PBtkUwPLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Create DataLoader to Every Datasets \"\"\"\n",
        "\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_tensor,batch_size=32,shuffle=True, num_workers=0)\n",
        "vali_loader=torch.utils.data.DataLoader(dataset=valid_tensor,batch_size=32,shuffle=True, num_workers=0)\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_tensor,batch_size=32,shuffle=True, num_workers=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2kIv7YUymWl",
        "colab_type": "code",
        "outputId": "3b31d86a-f148-4873-9f77-b3a800ef98cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "\"\"\"\n",
        "object from NN Model\n",
        "and print it\n",
        "\"\"\"\n",
        "vocab_size = len(word_to_index)+1\n",
        "embedding_dim = 300\n",
        "net = CNN(vocab_size, embedding_dim,torch.from_numpy(word_embedding))\n",
        "print(net)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (embedding): Embedding(400001, 300)\n",
            "  (conv1): Conv1d(903, 300, kernel_size=(2,), stride=(1,), padding=(1,))\n",
            "  (relu1): ReLU()\n",
            "  (dropout1): Dropout(p=0.6, inplace=False)\n",
            "  (conv2): Conv1d(300, 300, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (relu2): ReLU()\n",
            "  (dropout2): Dropout(p=0.6, inplace=False)\n",
            "  (conv3): Conv1d(300, 300, kernel_size=(4,), stride=(1,), padding=(1,))\n",
            "  (maxpool3): AvgPool1d(kernel_size=(2,), stride=(1,), padding=(1,))\n",
            "  (relu3): ReLU()\n",
            "  (dropout3): Dropout(p=0.6, inplace=False)\n",
            "  (fc): Linear(in_features=600, out_features=1, bias=True)\n",
            "  (dropout4): Dropout(p=0.5, inplace=False)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ewj9UOVymBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Learning rate 0.001\n",
        "create Binary Cross Entropy Loss function\n",
        "Create Adam optimizer to optimization parameters of NN ( Embedding , Linear Layers )\n",
        "\n",
        "\"\"\"\n",
        "lr=0.0003\n",
        "\n",
        "net.cuda()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer1 = torch.optim.Adam(net.conv1.parameters(), lr=lr)\n",
        "optimizer2 = torch.optim.Adam(net.conv2.parameters(), lr=lr)\n",
        "optimizer3 = torch.optim.Adam(net.conv3.parameters(), lr=lr)\n",
        "optimizer4 = torch.optim.Adam(net.fc.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8E6cZmfCdDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd1XfvzUylwy",
        "colab_type": "code",
        "outputId": "d52a7466-135d-4f68-907e-a973a4d39015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "\"\"\" 10 Number Epoch \"\"\"\n",
        "\n",
        "LtraininVis,LvalidVis=[],[]\n",
        "batch_size=32\n",
        "epochs = 15\n",
        "mnloss=np.Inf\n",
        "\n",
        "net.train() \n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  Taccuracy,Vaccuracy=[],[]\n",
        "  losses=[]\n",
        "  for inputs, labels in train_loader:\n",
        "\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()  \n",
        "\n",
        "\n",
        "    net.zero_grad()\n",
        "    \n",
        "    output= net(inputs.long())\n",
        "\n",
        "    Taccuracy.append(Accu(torch.round(output),labels))\n",
        "\n",
        "\n",
        "    loss = criterion(output.squeeze().float(), labels.float())\n",
        "\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer1.step()\n",
        "    optimizer2.step()\n",
        "    optimizer3.step()\n",
        "    optimizer4.step()\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    net.eval()\n",
        "    val_losses = []\n",
        "    \n",
        "\n",
        "    for inputs, labels in vali_loader:\n",
        "\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "\n",
        "      output= net(inputs.long())\n",
        "\n",
        "      Vaccuracy.append(Accu(torch.round(output),labels))\n",
        "\n",
        "      val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "      val_losses.append(val_loss.item())\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    LtraininVis.append(np.mean(losses))\n",
        "    LvalidVis.append(np.mean(val_losses))\n",
        "    \n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "          \"Tarining Loss: {:.6f}...\".format(np.mean(losses)),\n",
        "          \"Val Loss: {:.6f}\".format(np.mean(val_losses)),\n",
        "          \"Val Accu:{:.6f}\".format(np.mean(Vaccuracy)),\n",
        "          \"Training Accu:{:.6f}\".format(np.mean(Taccuracy)))\n",
        "    if mnloss>np.mean(val_losses):\n",
        "      mnloss=np.mean(val_losses)\n",
        "      print(\"Saving Model......\")\n",
        "      torch.save(net.state_dict(),\"liar.pkl\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/15... Tarining Loss: 0.678925... Val Loss: 0.676005 Val Accu:0.558783 Training Accu:0.560397\n",
            "Saving Model......\n",
            "Epoch: 2/15... Tarining Loss: 0.664528... Val Loss: 0.664403 Val Accu:0.611029 Training Accu:0.590311\n",
            "Saving Model......\n",
            "Epoch: 3/15... Tarining Loss: 0.659964... Val Loss: 0.656389 Val Accu:0.626471 Training Accu:0.605208\n",
            "Saving Model......\n",
            "Epoch: 4/15... Tarining Loss: 0.654204... Val Loss: 0.656230 Val Accu:0.620302 Training Accu:0.614053\n",
            "Saving Model......\n",
            "Epoch: 5/15... Tarining Loss: 0.650482... Val Loss: 0.654568 Val Accu:0.625286 Training Accu:0.612048\n",
            "Saving Model......\n",
            "Epoch: 6/15... Tarining Loss: 0.646066... Val Loss: 0.652182 Val Accu:0.635539 Training Accu:0.621384\n",
            "Saving Model......\n",
            "Epoch: 7/15... Tarining Loss: 0.640168... Val Loss: 0.650019 Val Accu:0.636193 Training Accu:0.633746\n",
            "Saving Model......\n",
            "Epoch: 8/15... Tarining Loss: 0.635876... Val Loss: 0.650725 Val Accu:0.635131 Training Accu:0.636360\n",
            "Epoch: 9/15... Tarining Loss: 0.633482... Val Loss: 0.652991 Val Accu:0.637990 Training Accu:0.639642\n",
            "Epoch: 10/15... Tarining Loss: 0.624291... Val Loss: 0.649447 Val Accu:0.631863 Training Accu:0.649233\n",
            "Saving Model......\n",
            "Epoch: 11/15... Tarining Loss: 0.618633... Val Loss: 0.652889 Val Accu:0.635580 Training Accu:0.658274\n",
            "Epoch: 12/15... Tarining Loss: 0.610641... Val Loss: 0.654152 Val Accu:0.631250 Training Accu:0.669379\n",
            "Epoch: 13/15... Tarining Loss: 0.602381... Val Loss: 0.675386 Val Accu:0.629984 Training Accu:0.673467\n",
            "Epoch: 14/15... Tarining Loss: 0.592208... Val Loss: 0.660203 Val Accu:0.635621 Training Accu:0.675727\n",
            "Epoch: 15/15... Tarining Loss: 0.581573... Val Loss: 0.671114 Val Accu:0.625694 Training Accu:0.691961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpuEG1o4sF6",
        "colab_type": "code",
        "outputId": "611611ca-d5c3-48d7-d978-4e4f2451e8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "\"\"\" Visualiaztion Learning Curve \"\"\"\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
        "ax1.plot(LtraininVis,label='Training Loss')\n",
        "ax1.plot(LvalidVis,label='Validation Loss')\n",
        "\n",
        "ax1.legend(frameon=False)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f24101730f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFpCAYAAADUTv+7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncCfMzMzMrAb/ASfJSL6H21zKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-mafcC5V_g",
        "colab_type": "code",
        "outputId": "d32f50c0-d2fe-4066-8c6a-bce05a6e0eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"Testing Model\"\"\"\n",
        "net.load_state_dict(torch.load(\"liar.pkl\"))\n",
        "testloss=[]\n",
        "testaccutacy=[]\n",
        "net.eval()\n",
        "\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "\n",
        "      output= net(inputs.long())\n",
        "\n",
        "      testaccutacy.append(Accu(torch.round(output),labels))\n",
        "\n",
        "      test_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "      testloss.append(val_loss.item())\n",
        "\n",
        "\n",
        "print(\"Testing Accuracy \",np.mean(testaccutacy))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy  0.6040360501567398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W40uK0NmyKiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}