{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quality text version1 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXF6qcUQTAVKWOCGFNKJuQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smara97/FakeNews/blob/master/quality_text_version1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI93yKBeR4d7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a7815be3-a5a2-48eb-e189-de32fbe2c56e"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from google.colab import files,drive\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import wordpunct_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from torch.autograd import Variable\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "import nltk\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXm1UJAJUdki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3b3302e-1efc-40f0-cc4f-7ba052dc77c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q415tJoOUZSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Read Dataset (Data Frame)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/train.tsv\",sep=\"\\t\",header=None)\n",
        "dfval=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/val.tsv\",sep=\"\\t\",header=None)\n",
        "dftest=pd.read_csv(\"/content/drive/My Drive/Datasets/liar-plus/test.tsv\",sep=\"\\t\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na44Z8v1U6K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "list of columns's Name \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cols=['index','ID','label','statement','subject','speaker',\n",
        "      'speaker_job','state','party','barely_true',\n",
        "      'false','half_true','mostly_true','pants_on_fire',\n",
        "      'context','justification']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_uLxy1_U9Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Add list cols to Data Frame columns\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain.columns=cols\n",
        "dfval.columns=cols\n",
        "dftest.columns=cols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pqHGQpZU9UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Make Datasets have only statement,subject,justification and label \n",
        "important Feauters to Training\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=dftrain.loc[:,['statement','subject','justification','label']]\n",
        "dfval=dfval.loc[:,['statement','subject','justification','label']]\n",
        "dftest=dftest.loc[:,['statement','subject','justification','label']]\n",
        "dftrain=dftrain.append(dfval)\n",
        "dftrain=dftrain.append(dftest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR9-dml-U9Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Drop NAN value and index column in Datasets \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dftrain=dftrain.dropna(axis=0)\n",
        "\n",
        "dftrain=dftrain.reset_index()\n",
        "\n",
        "dftrain=dftrain.drop(['index'],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGhGIdWiU9HG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "feae8af9-0c80-4afa-baf6-1c13124bcd51"
      },
      "source": [
        "\"\"\"  Show first two's row in dataset \"\"\"\n",
        "\n",
        "dftrain.head(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>justification</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>That's a premise that he fails to back up. Ann...</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>Surovell said the decline of coal \"started whe...</td>\n",
              "      <td>half-true</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement  ...      label\n",
              "0  Says the Annies List political group supports ...  ...      false\n",
              "1  When did the decline of coal start? It started...  ...  half-true\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBKdJia8VG6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "convert labels to 0,1 True or False  \n",
        "\n",
        "\"\"\"\n",
        "convertlabel = {\n",
        "\t'pants-fire': 0,\n",
        "\t'false': 0,\n",
        "\t'barely-true': 0,\n",
        "\t'half-true': 1,\n",
        "\t'mostly-true': 1,\n",
        "\t'true': 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRptkUuTVMbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Clean Text \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def clean(text):\n",
        "  text=text.lower()\n",
        "  stp=set(stopwords.words(\"english\"))\n",
        "  placesp = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "  removech= re.compile('[^0-9a-z #+_]')\n",
        "  st=WordNetLemmatizer()\n",
        "  text=re.sub(placesp,' ',text)\n",
        "  text=re.sub(removech,' ',text)\n",
        "  text=text.split()\n",
        "  text=[w for w in text if not w in stp]\n",
        "  text=[st.lemmatize(w) for w in text]\n",
        "  text=\" \".join(text)\n",
        "  text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yd0ktglVMXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Convert Labels dataset to 0,1 by Call convertlabel Function , \n",
        "sentence to indeces by call transfer_sent Function\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for i in range(dftrain.shape[0]):\n",
        "  dftrain.loc[i,'label']=convertlabel[dftrain.loc[i,'label']]\n",
        "  dftrain.loc[i,'statement']=clean(dftrain.loc[i,'statement'])\n",
        "  dftrain.loc[i,'subject']=clean(dftrain.loc[i,'subject'])\n",
        "  dftrain.loc[i,'justification']=clean(dftrain.loc[i,'justification'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8-qe-gAVMVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statements=dftrain['statement'].values\n",
        "statements=[statement.split() for statement in statements]\n",
        "\n",
        "subjects=dftrain['subject'].values\n",
        "subjects=[subject.split() for subject in subjects]\n",
        "\n",
        "justifications=dftrain['justification'].values\n",
        "justifications=[justification.split() for justification in justifications]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rJavjFlVMR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_statement=statements[0]\n",
        "user_justification=justifications[0]\n",
        "user_subject=subjects[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdFAzgITR50v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smoother = SmoothingFunction()\n",
        "\n",
        "score_statement = sentence_bleu(statements, user_statement, smoothing_function=smoother.method2,emulate_multibleu=True)\n",
        "score_subject = sentence_bleu(subjects, user_subject, smoothing_function=smoother.method2,emulate_multibleu=True)\n",
        "score_justification = sentence_bleu(justifications, user_justification,smoothing_function=smoother.method2, emulate_multibleu=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB34dvr3SHLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2728ee79-5e7a-4e29-a6ce-877da4b641fb"
      },
      "source": [
        "all_score=(score_statement+score_subject+score_justification)/3\n",
        "print(all_score)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8648666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt3cO3BgYMuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}